# FluxPlore
FluxPlore: Exploring the Dynamic Contexts of AI Behavior

# Description

FluxPlore is a ground-breaking project focused on uncovering, understanding, and documenting the emergent properties of AI behaviors, specifically in the context of language models. By creating a robust and comprehensive framework for testing potential context biases, FluxPlore strives to explore the shifting sands of AI cognition, charting how various factors dynamically influence AI responses.

# Main Aims

Uncover Contextual Influences: FluxPlore aims to delve deep into how context affects AI responses. By analyzing sequential ambiguity, contradictory information, multiple contexts, and more, the project seeks to uncover the various nuances of how context influences AI outputs.

Test AI Robustness: FluxPlore aims to develop a diverse range of tests to scrutinize AI performance under various contextual circumstances. These tests will not only gauge the AI's cognitive biases but also assess its adaptability and agility when faced with changing contexts.

Promote AI Fairness and Transparency: By providing insights into how AI models react to different contexts, FluxPlore aims to help develop strategies for mitigating undue biases, promoting fairer and more transparent AI systems for future generations.

# Evaluation of AI bias model with metrics and criteria

1. Ambiguity Resolution (Testing for anchoring and availability bias)
1.1. Single Step Ambiguity
1.1.1. Anchoring Bias Test
- Measure the degree of influence of the initial information (anchor) on the AI's responses.
1.1.2. Availability Bias Test
- Measure the dependence of AI responses on recently learned or frequently encountered information.
1.2. Multi-Step Ambiguity
1.2.1. Sequential Anchoring Bias Test
- Measure how strongly the initial anchor affects responses over a sequence of interrelated prompts.
1.2.2. Multilayered Availability Bias Test
- Measure the AI's reliance on frequently encountered information in complex, multilayered scenarios.
1.3. Problem-Solving Ambiguity
1.3.1. Problem-Specific Anchoring Bias Test
- Measure the influence of initial problem framing on subsequent problem-solving attempts.
1.3.2. Problem-Specific Availability Bias Test
- Measure the AI's reliance on familiar problem-solving methods even when they may not be optimal.
1.4. Relevance Testing
1.4.1. Contextual Relevance Bias Test
- Measure the AI's ability to determine which aspects of a complex scenario are most relevant.
1.4.2. Informational Relevance Bias Test
- Measure the degree to which the AI preferences recent or frequent information over older or less common information.

2. Context Shift (Testing for confirmation bias and functional fixedness)
2.1. Progressive Context Shifts
2.1.1. Binary Context Shift Confirmation Bias Test
- Measure the AI's ability to adapt when a binary (two-option) context suddenly changes.
2.1.2. Multiple Progressive Shifts Confirmation Bias Test
- Measure the AI's adaptability when the context changes multiple times in a sequence.
2.2. Sudden Context Shift
2.2.1. Binary Sudden Shift Confirmation Bias Test
- Measure the AI's ability to respond correctly when a binary context shifts unexpectedly.
2.2.2. Multi-Domain Sudden Shift Confirmation Bias Test
- Measure the AI's adaptability when context shifts across multiple domains (e.g., from sports to finance).
2.3. Simultaneous Contexts
2.3.1. Dual Context Management Functional Fixedness Test
- Measure the AI's ability to juggle two contexts simultaneously without confusing the information relevant to each.
2.3.2. Multi-Domain Context Management Functional Fixedness Test
- Measure the AI's ability to manage multiple simultaneous contexts across various domains.
2.4. Context Revisiting
2.4.1. Single Context Revisiting Confirmation Bias Test
- Measure the AI's tendency to resort to previously used context, even when it may no longer be valid.
2.4.2. Multiple Contexts Revisiting Confirmation Bias Test
- Measure the AI's ability to navigate and adapt when previously encountered contexts are revisited in a new light.

3. Reframing Techniques (Testing for framing effect and status quo bias)
3.1. Metaphorical Reframing
3.1.1. Framing Effect Test
- Measure the AI's susceptibility to changes in problem framing using different metaphors.
3.1.2. Status Quo Bias Test
- Measure the degree to which the AI defaults to a status quo solution when faced with a metaphorically reframed problem.
3.2. Spatial Temporal Reframing
3.2.1. Spatial Temporal Framing Effect Test
- Measure how the AI's responses shift when the time or space context of a problem is altered.
3.2.2. Spatial Temporal Status Quo Bias Test
- Measure the AI's tendency to default to status quo solutions when the spatial or temporal framing of a problem changes.
3.3. Role Reframing
3.3.1. Role Framing Effect Test
- Measure the extent to which the AI's responses shift when the roles of entities in a problem are changed.
3.3.2. Role Status Quo Bias Test
- Measure the AI's tendency to revert to status quo understandings of roles even when they have been explicitly reframed.
3.4. Emotional Reframing
3.4.1. Emotional Framing Effect Test
- Measure the influence of different emotional framings of a problem on the AI's responses.
3.4.2. Emotional Status Quo Bias Test
- Measure the AI's tendency to default to a status quo emotional understanding of a situation, even when it is reframed.
